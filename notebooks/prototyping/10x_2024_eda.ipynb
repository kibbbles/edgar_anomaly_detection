{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-X 2024 Data Quality Assessment\n",
    "\n",
    "**Purpose:** Evaluate the raw 10-x_2024.zip file to assess:\n",
    "1. File format (HTML vs. cleaned text)\n",
    "2. Table formatting quality\n",
    "3. Comparison with existing cleaned data in `data/external/clean/`\n",
    "4. Recommendations for usage in RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import re\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. File Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# File paths\nraw_zip = r'C:\\Users\\kabec\\Documents\\edgar_anomaly_detection\\data\\external\\raw\\10-x_2024.zip'\nclean_zip = r'C:\\Users\\kabec\\Documents\\edgar_anomaly_detection\\data\\external\\clean\\10-X_C_2024.zip'\n\n# Open both files\nz_raw = zipfile.ZipFile(raw_zip)\nz_clean = zipfile.ZipFile(clean_zip)\n\nprint(f\"Raw zip file size: {Path(raw_zip).stat().st_size / 1e9:.2f} GB\")\nprint(f\"Clean zip file size: {Path(clean_zip).stat().st_size / 1e9:.2f} GB\")\nprint(f\"\\nRaw files: {len(z_raw.namelist()):,}\")\nprint(f\"Clean files: {len(z_clean.namelist()):,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample File Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw .txt files: 26,014\n",
      "Clean .txt files: 26,014\n",
      "\n",
      "Sampled files for comparison:\n",
      "  - 2024/QTR3/20240807_10-Q_edgar_data_1043186_0001437749-24-025209.txt\n",
      "  - 2024/QTR2/20240401_10-K_edgar_data_1577310_0000950170-24-039217.txt\n",
      "  - 2024/QTR2/20240423_10-Q_edgar_data_1408198_0001408198-24-000075.txt\n",
      "  - 2024/QTR1/20240327_10-K_edgar_data_1895618_0001213900-24-026681.txt\n",
      "  - 2024/QTR3/20240808_10-Q_edgar_data_849869_0000849869-24-000128.txt\n"
     ]
    }
   ],
   "source": [
    "# Get list of txt files (exclude directories)\n",
    "raw_files = [f for f in z_raw.namelist() if f.endswith('.txt')]\n",
    "clean_files = [f for f in z_clean.namelist() if f.endswith('.txt')]\n",
    "\n",
    "print(f\"Raw .txt files: {len(raw_files):,}\")\n",
    "print(f\"Clean .txt files: {len(clean_files):,}\")\n",
    "\n",
    "# Sample 5 random files for comparison\n",
    "sample_files = random.sample([f for f in raw_files if f in clean_files], 5)\n",
    "print(f\"\\nSampled files for comparison:\")\n",
    "for f in sample_files:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HTML Content Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>raw_size</th>\n",
       "      <th>clean_size</th>\n",
       "      <th>raw_html_tags</th>\n",
       "      <th>clean_html_tags</th>\n",
       "      <th>raw_tables</th>\n",
       "      <th>clean_tables</th>\n",
       "      <th>raw_has_html</th>\n",
       "      <th>clean_has_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240807_10-Q_edgar_data_1043186_0001437749-24...</td>\n",
       "      <td>5423966</td>\n",
       "      <td>77537</td>\n",
       "      <td>86334</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240401_10-K_edgar_data_1577310_0000950170-24...</td>\n",
       "      <td>4116743</td>\n",
       "      <td>398378</td>\n",
       "      <td>65075</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240423_10-Q_edgar_data_1408198_0001408198-24...</td>\n",
       "      <td>7402510</td>\n",
       "      <td>117241</td>\n",
       "      <td>124470</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240327_10-K_edgar_data_1895618_0001213900-24...</td>\n",
       "      <td>5090888</td>\n",
       "      <td>343313</td>\n",
       "      <td>98264</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240808_10-Q_edgar_data_849869_0000849869-24-...</td>\n",
       "      <td>5211667</td>\n",
       "      <td>77927</td>\n",
       "      <td>89355</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  raw_size  clean_size  \\\n",
       "0  20240807_10-Q_edgar_data_1043186_0001437749-24...   5423966       77537   \n",
       "1  20240401_10-K_edgar_data_1577310_0000950170-24...   4116743      398378   \n",
       "2  20240423_10-Q_edgar_data_1408198_0001408198-24...   7402510      117241   \n",
       "3  20240327_10-K_edgar_data_1895618_0001213900-24...   5090888      343313   \n",
       "4  20240808_10-Q_edgar_data_849869_0000849869-24-...   5211667       77927   \n",
       "\n",
       "   raw_html_tags  clean_html_tags  raw_tables  clean_tables  raw_has_html  \\\n",
       "0          86334               39          12             0          True   \n",
       "1          65075               67          15             0          True   \n",
       "2         124470               39           1             0          True   \n",
       "3          98264               47           0             0          True   \n",
       "4          89355               43           1             0          True   \n",
       "\n",
       "   clean_has_html  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_file(zip_file, filename):\n",
    "    \"\"\"Analyze a single file for HTML content and tables.\"\"\"\n",
    "    content = zip_file.read(filename).decode('utf-8', errors='ignore')\n",
    "    \n",
    "    # Basic stats\n",
    "    stats = {\n",
    "        'filename': filename.split('/')[-1],\n",
    "        'size_chars': len(content),\n",
    "        'html_tags': len(re.findall(r'<[^>]+>', content)),\n",
    "    }\n",
    "    \n",
    "    # Find HTML content\n",
    "    html_match = re.search(r'<html>.*?</html>', content, re.DOTALL | re.IGNORECASE)\n",
    "    if html_match:\n",
    "        html_content = html_match.group(0)\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        stats['tables'] = len(soup.find_all('table'))\n",
    "        stats['has_html'] = True\n",
    "    else:\n",
    "        stats['tables'] = 0\n",
    "        stats['has_html'] = False\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze sample files\n",
    "results = []\n",
    "for filename in sample_files:\n",
    "    raw_stats = analyze_file(z_raw, filename)\n",
    "    clean_stats = analyze_file(z_clean, filename)\n",
    "    \n",
    "    results.append({\n",
    "        'file': raw_stats['filename'],\n",
    "        'raw_size': raw_stats['size_chars'],\n",
    "        'clean_size': clean_stats['size_chars'],\n",
    "        'raw_html_tags': raw_stats['html_tags'],\n",
    "        'clean_html_tags': clean_stats['html_tags'],\n",
    "        'raw_tables': raw_stats['tables'],\n",
    "        'clean_tables': clean_stats['tables'],\n",
    "        'raw_has_html': raw_stats['has_html'],\n",
    "        'clean_has_html': clean_stats['has_html']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Table Quality Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Found 12 tables in 20240807_10-Q_edgar_data_1043186_0001437749-24-025209.txt\n",
      "\n",
      "=== First table structure (first 500 chars) ===\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width: 100%; text-indent: 0px;\">\n",
      "<tr style=\"vertical-align: top;\">\n",
      "<td style=\"width: 18pt;\">\n",
      "<p style='margin: 0pt; text-align: left; font-family: \"Times New Roman\", Times, serif; font-size: 10pt;'>1.</p>\n",
      "</td>\n",
      "<td style=\"width: auto;\">\n",
      "<p style='margin: 0pt; text-align: left; font-family: \"Times New Roman\", Times, serif; font-size: 10pt;'>I have reviewed this Quarterly Report on Form 10-Q of Stabilis Solutions, Inc.;</p>\n",
      "</td>\n",
      "</tr>\n",
      "</tab\n",
      "\n",
      "=== Attempting to parse table to DataFrame ===\n",
      "[WARN] Could not parse table: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabec\\AppData\\Local\\Temp\\ipykernel_42836\\1156944277.py:21: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(str(tables[0]))\n"
     ]
    }
   ],
   "source": [
    "# Pick a file with tables and examine table structure\n",
    "sample_with_tables = sample_files[0]\n",
    "\n",
    "# Raw version\n",
    "raw_content = z_raw.read(sample_with_tables).decode('utf-8', errors='ignore')\n",
    "html_match = re.search(r'<html>.*?</html>', raw_content, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "if html_match:\n",
    "    soup = BeautifulSoup(html_match.group(0), 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    print(f\"[OK] Found {len(tables)} tables in {sample_with_tables.split('/')[-1]}\")\n",
    "    print(\"\\n=== First table structure (first 500 chars) ===\")\n",
    "    if tables:\n",
    "        print(str(tables[0])[:500])\n",
    "        \n",
    "        # Try to extract table data\n",
    "        print(\"\\n=== Attempting to parse table to DataFrame ===\")\n",
    "        try:\n",
    "            # Read tables with pandas\n",
    "            dfs = pd.read_html(str(tables[0]))\n",
    "            if dfs:\n",
    "                print(f\"[OK] Successfully parsed table with shape: {dfs[0].shape}\")\n",
    "                print(\"\\nFirst few rows:\")\n",
    "                print(dfs[0].head())\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Could not parse table: {e}\")\n",
    "else:\n",
    "    print(\"[WARN] No HTML content found in sample file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Quality: Raw vs. Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW VERSION (first 1000 chars) ===\n",
      "ex_680480.htm Exhibit 31.1 CERTIFICATIONS I, Westervelt T. Ballard, Jr., certify that: 1. I have reviewed this Quarterly Report on Form 10-Q of Stabilis Solutions, Inc.; 2. Based on my knowledge, this report does not contain any untrue statement of a material fact or omit to state a material fact necessary to make the statements made, in light of the circumstances under which such statements were made, not misleading with respect to the period covered by this report; 3. Based on my knowledge, the financial statements, and other financial information included in this report, fairly present in all material respects the financial condition, results of operations and cash flows of the registrant as of, and for, the periods presented in this report; 4. The registrant's other certifying officer(s) and I are responsible for establishing and maintaining disclosure controls and procedures (as defined in Exchange Act Rules 13a-15(e) and l5d-15(e)) and internal control over financial reporting (a\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== CLEAN VERSION (first 1000 chars) ===\n",
      "<Header>\n",
      "<FileStats>\n",
      "    <FileName>20240807_10-Q_edgar_data_1043186_0001437749-24-025209.txt</FileName>\n",
      "    <GrossFileSize>5423966</GrossFileSize>\n",
      "    <NetFileSize>73979</NetFileSize>\n",
      "    <NonText_DocumentType_Chars>939332</NonText_DocumentType_Chars>\n",
      "    <HTML_Chars>1638555</HTML_Chars>\n",
      "    <XBRL_Chars>1313370</XBRL_Chars>\n",
      "    <XML_Chars>1325570</XML_Chars>\n",
      "    <N_Exhibits>8</N_Exhibits>\n",
      "</FileStats>\n",
      "<SEC-Header>\n",
      "0001437749-24-025209.hdr.sgml : 20240807\n",
      "<ACCEPTANCE-DATETIME>20240807164406\n",
      "ACCESSION NUMBER:\t\t0001437749-24-025209\n",
      "CONFORMED SUBMISSION TYPE:\t10-Q\n",
      "PUBLIC DOCUMENT COUNT:\t\t70\n",
      "CONFORMED PERIOD OF REPORT:\t20240630\n",
      "FILED AS OF DATE:\t\t20240807\n",
      "DATE AS OF CHANGE:\t\t20240807\n",
      "\n",
      "FILER:\n",
      "\n",
      "\tCOMPANY DATA:\t\n",
      "\t\tCOMPANY CONFORMED NAME:\t\t\tStabilis Solutions, Inc.\n",
      "\t\tCENTRAL INDEX KEY:\t\t\t0001043186\n",
      "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tNATURAL GAS DISTRIBUTION [4924]\n",
      "\t\tORGANIZATION NAME:           \t01 Energy & Transportation\n",
      "\t\tIRS NUMBER:\t\t\t\t593410234\n",
      "\t\tSTATE OF INCO\n"
     ]
    }
   ],
   "source": [
    "# Compare text extraction from both versions\n",
    "sample_file = sample_files[0]\n",
    "\n",
    "raw_content = z_raw.read(sample_file).decode('utf-8', errors='ignore')\n",
    "clean_content = z_clean.read(sample_file).decode('utf-8', errors='ignore')\n",
    "\n",
    "# Extract text from raw HTML\n",
    "html_match = re.search(r'<html>.*?</html>', raw_content, re.DOTALL | re.IGNORECASE)\n",
    "if html_match:\n",
    "    soup = BeautifulSoup(html_match.group(0), 'html.parser')\n",
    "    raw_text = soup.get_text(separator=' ', strip=True)\n",
    "else:\n",
    "    raw_text = raw_content\n",
    "\n",
    "print(\"=== RAW VERSION (first 1000 chars) ===\")\n",
    "print(raw_text[:1000])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"=== CLEAN VERSION (first 1000 chars) ===\")\n",
    "print(clean_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARISON SUMMARY ===\n",
      "\n",
      "File Count:\n",
      "  Raw:   26,014 files\n",
      "  Clean: 26,014 files\n",
      "\n",
      "Average File Size (from 5 samples):\n",
      "  Raw:   5,449,155 chars\n",
      "  Clean: 202,879 chars\n",
      "  Reduction: 96.3%\n",
      "\n",
      "HTML Tags (from 5 samples):\n",
      "  Raw:   92,700 tags/file\n",
      "  Clean: 47 tags/file\n",
      "\n",
      "Tables (from 5 samples):\n",
      "  Raw:   5.8 tables/file\n",
      "  Clean: 0.0 tables/file\n",
      "\n",
      "  Files with HTML:\n",
      "    Raw:   5/5 files\n",
      "    Clean: 0/5 files\n"
     ]
    }
   ],
   "source": [
    "print(\"=== COMPARISON SUMMARY ===\")\n",
    "print(f\"\\nFile Count:\")\n",
    "print(f\"  Raw:   {len(raw_files):,} files\")\n",
    "print(f\"  Clean: {len(clean_files):,} files\")\n",
    "\n",
    "print(f\"\\nAverage File Size (from {len(results)} samples):\")\n",
    "print(f\"  Raw:   {df['raw_size'].mean():,.0f} chars\")\n",
    "print(f\"  Clean: {df['clean_size'].mean():,.0f} chars\")\n",
    "print(f\"  Reduction: {(1 - df['clean_size'].mean() / df['raw_size'].mean()) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nHTML Tags (from {len(results)} samples):\")\n",
    "print(f\"  Raw:   {df['raw_html_tags'].mean():,.0f} tags/file\")\n",
    "print(f\"  Clean: {df['clean_html_tags'].mean():,.0f} tags/file\")\n",
    "\n",
    "print(f\"\\nTables (from {len(results)} samples):\")\n",
    "print(f\"  Raw:   {df['raw_tables'].mean():,.1f} tables/file\")\n",
    "print(f\"  Clean: {df['clean_tables'].mean():,.1f} tables/file\")\n",
    "print(f\"\\n  Files with HTML:\")\n",
    "print(f\"    Raw:   {df['raw_has_html'].sum()}/{len(df)} files\")\n",
    "print(f\"    Clean: {df['clean_has_html'].sum()}/{len(df)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations\n",
    "\n",
    "Based on the analysis above:\n",
    "\n",
    "### Key Findings\n",
    "1. **Raw files contain full HTML** with all formatting, tables, and structure preserved\n",
    "2. **Clean files are pre-processed** - HTML stripped, exhibits removed, significantly smaller\n",
    "3. **Table preservation**: Raw files retain table structure; clean files have tables converted to text\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "**For RAG Pipeline:**\n",
    "- **Use CLEANED data** (`data/external/clean/10-X_C_2024.zip`) for current RAG pipeline\n",
    "  - Already processed and text-extracted\n",
    "  - 94% smaller file size\n",
    "  - Easier to chunk and embed\n",
    "  - Notre Dame SRAF already did the heavy lifting (HTML parsing, exhibit removal)\n",
    "\n",
    "**For Table-Specific Analysis (Future Work):**\n",
    "- **Keep raw data** for specialized table extraction if needed\n",
    "  - Financial statements tables\n",
    "  - Structured data extraction\n",
    "  - Custom HTML parsing\n",
    "\n",
    "**Action Items:**\n",
    "1. Move `10-x_2024.zip` to `data/external/raw/` (create folder if needed)\n",
    "2. Continue using cleaned data in `data/external/clean/` for RAPTOR pipeline\n",
    "3. Delete this notebook after reviewing findings (per CLAUDE.md guidelines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}